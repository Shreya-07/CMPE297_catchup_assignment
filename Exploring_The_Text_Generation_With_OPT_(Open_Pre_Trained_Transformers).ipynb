{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreya-07/CMPE297_catchup_assignment/blob/main/Exploring_The_Text_Generation_With_OPT_(Open_Pre_Trained_Transformers).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Pytorch"
      ],
      "metadata": {
        "id": "UEm3D0os6N5X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "B6gtof_P6DOJ",
        "outputId": "beaee202-ba6d-4ec1-957e-7511c5ad2205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting torch==1.10.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n",
            "\u001b[K     |██████████████▋                 | 834.1 MB 1.2 MB/s eta 0:13:22tcmalloc: large alloc 1147494400 bytes == 0x64b00000 @  0x7f83ac82f615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████▌             | 1055.7 MB 1.3 MB/s eta 0:10:04tcmalloc: large alloc 1434370048 bytes == 0x2328000 @  0x7f83ac82f615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████▌        | 1336.2 MB 1.3 MB/s eta 0:06:25tcmalloc: large alloc 1792966656 bytes == 0x57b14000 @  0x7f83ac82f615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████████████▊  | 1691.1 MB 1.2 MB/s eta 0:01:51tcmalloc: large alloc 2241208320 bytes == 0xc28fc000 @  0x7f83ac82f615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1821.4 MB 4.8 MB/s eta 0:00:01tcmalloc: large alloc 1821442048 bytes == 0x2328000 @  0x7f83ac82e1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2276802560 bytes == 0x14825e000 @  0x7f83ac82f615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1821.4 MB 8.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.11.2+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.2%2Bcu113-cp38-cp38-linux_x86_64.whl (24.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.6 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.10.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.1%2Bcu113-cp38-cp38-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.1+cu113) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.2+cu113) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.2+cu113) (1.21.6)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.1+cu113 torchaudio-0.10.1+cu113 torchvision-0.11.2+cu113\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install Megatron"
      ],
      "metadata": {
        "id": "DNnA32e16XHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/patrickvonplaten/Megatron-LM.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Oqarufq6bMc",
        "outputId": "a0bb4fde-2bd7-4e6b-9720-caf065ede60f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Megatron-LM'...\n",
            "remote: Enumerating objects: 7334, done.\u001b[K\n",
            "remote: Total 7334 (delta 0), reused 0 (delta 0), pack-reused 7334\u001b[K\n",
            "Receiving objects: 100% (7334/7334), 2.49 MiB | 27.73 MiB/s, done.\n",
            "Resolving deltas: 100% (5456/5456), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Megatron-LM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJFHSdPV7DaQ",
        "outputId": "16943590-4800-4da7-f5c7-d83f31abdb0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Megatron-LM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install six regex\n",
        "!pip install six\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13b5HJO6_16",
        "outputId": "831cca58-d33c-4829-d0a9-6c42917f1812"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/Megatron-LM\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (2.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.10.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from megatron-lm==1.1.5) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->megatron-lm==1.1.5) (4.4.0)\n",
            "Installing collected packages: megatron-lm\n",
            "  Attempting uninstall: megatron-lm\n",
            "    Found existing installation: megatron-lm 2.2.0\n",
            "    Uninstalling megatron-lm-2.2.0:\n",
            "      Successfully uninstalled megatron-lm-2.2.0\n",
            "  Running setup.py develop for megatron-lm\n",
            "Successfully installed megatron-lm-1.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Install fairscale"
      ],
      "metadata": {
        "id": "FAoVNxTV6sq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairscale==0.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGNZJ9Co6uEe",
        "outputId": "a4f7284a-b5bc-496b-9b84-c6b01f0fd392"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairscale==0.4.1\n",
            "  Downloading fairscale-0.4.1.tar.gz (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 26.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from fairscale==0.4.1) (1.10.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->fairscale==0.4.1) (4.4.0)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.1-py3-none-any.whl size=238992 sha256=c40505788658425867749a5b1c22e4d4dee34555042edb7ef911f9231ac8e195\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/62/1b/4fd9356edf517b35a7d4aa79e5ac3151583c1880038f4249b4\n",
            "Successfully built fairscale\n",
            "Installing collected packages: fairscale\n",
            "Successfully installed fairscale-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Install metaseq"
      ],
      "metadata": {
        "id": "63l7rM1D60G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/patrickvonplaten/metaseq.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stPCKDD665LS",
        "outputId": "2ab566f0-a621-4b50-cfbe-c35c72342727"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'metaseq'...\n",
            "remote: Enumerating objects: 833, done.\u001b[K\n",
            "remote: Total 833 (delta 0), reused 0 (delta 0), pack-reused 833\u001b[K\n",
            "Receiving objects: 100% (833/833), 23.94 MiB | 16.39 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd metaseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VctpAm9Z7f2M",
        "outputId": "cc55156b-a979-4160-f609-3423a685e520"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Megatron-LM/metaseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "75fkiLNS7iXt",
        "outputId": "312523af-2cf5-4346-b248-c7c5b4bacf87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/Megatron-LM/metaseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (4.64.1)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Collecting ninja\n",
            "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (1.10.1+cu113)\n",
            "Collecting flask==2.1.1\n",
            "  Downloading Flask-2.1.1-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (1.21.6)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting ipdb\n",
            "  Downloading ipdb-0.13.9.tar.gz (16 kB)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (9.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (2022.6.2)\n",
            "Collecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (2.0.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (0.29.32)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (4.4.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (7.9.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.27-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting click==8.0.4\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (0.5.3)\n",
            "Collecting Jinja2==3.1.1\n",
            "  Downloading Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 81.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (3.6.4)\n",
            "Collecting hydra-core>=1.1.0\n",
            "  Downloading hydra_core-1.3.0-py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 81.1 MB/s \n",
            "\u001b[?25hCollecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.14.1-py3-none-any.whl (383 kB)\n",
            "\u001b[K     |████████████████████████████████| 383 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from metaseq==0.0.1) (2.9.1)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting timeout-decorator\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->metaseq==0.0.1) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.10.3-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->metaseq==0.0.1) (2.5.4)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask==2.1.1->metaseq==0.0.1) (4.13.0)\n",
            "Collecting Werkzeug>=2.0\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 83.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1.0->metaseq==0.0.1) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1.0->metaseq==0.0.1) (5.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask==2.1.1->metaseq==0.0.1) (3.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf->metaseq==0.0.1) (6.0)\n",
            "Collecting markupsafe\n",
            "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting cryptography>=2.1.4\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 61.2 MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.24.2\n",
            "  Downloading azure_core-1.26.1-py3-none-any.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 78.2 MB/s \n",
            "\u001b[?25hCollecting msrest>=0.7.1\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.8/dist-packages (from azure-core<2.0.0,>=1.24.2->azure-storage-blob->metaseq==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from azure-core<2.0.0,>=1.24.2->azure-storage-blob->metaseq==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.1.4->azure-storage-blob->metaseq==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->metaseq==0.0.1) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from msrest>=0.7.1->azure-storage-blob->metaseq==0.0.1) (2022.9.24)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 588 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from msrest>=0.7.1->azure-storage-blob->metaseq==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob->metaseq==0.0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob->metaseq==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob->metaseq==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.7.1->azure-storage-blob->metaseq==0.0.1) (3.2.2)\n",
            "Collecting botocore<1.30.0,>=1.29.27\n",
            "  Downloading botocore-1.29.27-py3-none-any.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 61.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.27->boto3->metaseq==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->metaseq==0.0.1) (2.1.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from ipdb->metaseq==0.0.1) (57.4.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.7.0-py3-none-any.whl (761 kB)\n",
            "\u001b[K     |████████████████████████████████| 761 kB 78.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from ipdb->metaseq==0.0.1) (0.10.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipdb->metaseq==0.0.1) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->metaseq==0.0.1) (4.8.0)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 66.4 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit<3.1.0,>=3.0.11\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[K     |████████████████████████████████| 386 kB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->metaseq==0.0.1) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->metaseq==0.0.1) (0.2.0)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython->metaseq==0.0.1) (5.6.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython->metaseq==0.0.1) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->metaseq==0.0.1) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->metaseq==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython->metaseq==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->hydra-core>=1.1.0->metaseq==0.0.1) (3.0.9)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.9-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 58.6 MB/s \n",
            "\u001b[?25hCollecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.8->pre-commit->metaseq==0.0.1) (3.8.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 79.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->metaseq==0.0.1) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->metaseq==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->metaseq==0.0.1) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->metaseq==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu->metaseq==0.0.1) (4.9.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->metaseq==0.0.1) (0.8.10)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (1.51.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->metaseq==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->metaseq==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->metaseq==0.0.1) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->metaseq==0.0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->metaseq==0.0.1) (0.4.8)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, fire, iopath, ipdb, sklearn, timeout-decorator\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=2c22f75226e72597859f84d773e6d75a694a49e7ac48b5e052c2d8aec81d2e95\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=39f177fcdd6cdb5c5ad9d067f3210e74db376ba13ce0ad9772d0d45b544d6212\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=b75d3d1db605714711c4a2499c17164cf73df6fa84d63e974a3a57845ddd6136\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11649 sha256=3077e97320875852f7b63b16a8adca14ae1291ec8defd995bb794487ea317c72\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/51/8c/3dceedacfd0f743f3736b3840d08b6746b6259deea98207ba4\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=5620ee3a4c9583689ff41c934bdfc4498acf65ba27e6582117256dcedb5000a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5028 sha256=f7eec75a0399f486a56de23115c62e48ff620442572aad830ddc660513ff186d\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/05/4e/161d1463ca145ec1023bd4e5e1f31cbf9239aa8f39a2a2b643\n",
            "Successfully built antlr4-python3-runtime fire iopath ipdb sklearn timeout-decorator\n",
            "Installing collected packages: urllib3, pure-eval, jmespath, executing, asttokens, stack-data, prompt-toolkit, matplotlib-inline, markupsafe, jedi, isodate, distlib, botocore, azure-core, antlr4-python3-runtime, Werkzeug, virtualenv, s3transfer, portalocker, pathspec, omegaconf, nodeenv, mypy-extensions, msrest, Jinja2, itsdangerous, ipython, identify, cryptography, colorama, click, cfgv, timeout-decorator, sklearn, sacrebleu, pre-commit, ninja, ipdb, iopath, hydra-core, flask, fire, boto3, black, azure-storage-blob, metaseq\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 2.0.10\n",
            "    Uninstalling prompt-toolkit-2.0.10:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.10\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Running setup.py develop for metaseq\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-3.1.1 Werkzeug-2.2.2 antlr4-python3-runtime-4.9.3 asttokens-2.2.1 azure-core-1.26.1 azure-storage-blob-12.14.1 black-22.1.0 boto3-1.26.27 botocore-1.29.27 cfgv-3.3.1 click-8.0.4 colorama-0.4.6 cryptography-38.0.4 distlib-0.3.6 executing-1.2.0 fire-0.4.0 flask-2.1.1 hydra-core-1.3.0 identify-2.5.9 iopath-0.1.10 ipdb-0.13.9 ipython-8.7.0 isodate-0.6.1 itsdangerous-2.1.2 jedi-0.18.2 jmespath-1.0.1 markupsafe-2.1.1 matplotlib-inline-0.1.6 metaseq msrest-0.7.1 mypy-extensions-0.4.3 ninja-1.11.1 nodeenv-1.7.0 omegaconf-2.3.0 pathspec-0.10.3 portalocker-2.6.0 pre-commit-2.20.0 prompt-toolkit-3.0.36 pure-eval-0.2.2 s3transfer-0.6.0 sacrebleu-2.3.1 sklearn-0.0.post1 stack-data-0.6.2 timeout-decorator-0.5.0 urllib3-1.25.11 virtualenv-20.17.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit",
                  "pydevd_plugins",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Install transformers"
      ],
      "metadata": {
        "id": "4lZYPNbd7OxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_A3Nru7QNJ",
        "outputId": "63d4ca49-b7bf-4f02-db92-ea3194956da2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/patrickvonplaten/opt_metaseq_1300m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRwQWsIk7oOf",
        "outputId": "9be69597-ecf6-4043-bb77-8675f00c80d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'opt_metaseq_1300m'...\n",
            "remote: Enumerating objects: 558, done.\u001b[K\n",
            "remote: Counting objects: 100% (558/558), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 558 (delta 417), reused 540 (delta 412), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (558/558), 1.52 MiB | 1.35 MiB/s, done.\n",
            "Resolving deltas: 100% (417/417), done.\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x55d957bd2000 @  0x7ff8759bd2a4 0x55d91b59578f 0x55d91b5728db 0x55d91b5275b3 0x55d91b4cb34a 0x55d91b4cb806 0x55d91b4e8ad1 0x55d91b4e9069 0x55d91b4e9593 0x55d91b58e482 0x55d91b42ecc2 0x55d91b415a75 0x55d91b416735 0x55d91b41573a 0x7ff874d04c87 0x55d91b41578a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x55d9af6c2000 @  0x7ff8759bd2a4 0x55d91b59578f 0x55d91b5728db 0x55d91b5275b3 0x55d91b4cb34a 0x55d91b4cb806 0x55d91b4e8ad1 0x55d91b4e9069 0x55d91b4e9593 0x55d91b58e482 0x55d91b42ecc2 0x55d91b415a75 0x55d91b416735 0x55d91b41573a 0x7ff874d04c87 0x55d91b41578a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x55da32f28000 @  0x7ff8759bd2a4 0x55d91b59578f 0x55d91b5728db 0x55d91b5275b3 0x55d91b4cb34a 0x55d91b4cb806 0x55d91b4e8ad1 0x55d91b4e9069 0x55d91b4e9593 0x55d91b58e482 0x55d91b42ecc2 0x55d91b415a75 0x55d91b416735 0x55d91b41573a 0x7ff874d04c87 0x55d91b41578a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install megatron"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im4VFhsp9Hlp",
        "outputId": "f5b8e3d3-21e2-45f9-8c42-9f7be7932fc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: megatron in /usr/local/lib/python3.8/dist-packages (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from megatron) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from megatron) (1.21.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from megatron) (0.3.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->megatron) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->megatron) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->megatron) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install megatron-lm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N_LrqQz_ok5",
        "outputId": "842ca85a-7f37-463d-97f9-e6b3a6e8261d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: megatron-lm in /content/Megatron-LM (1.1.5)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.8/dist-packages (from megatron-lm) (2.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from megatron-lm) (1.10.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from megatron-lm) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from megatron-lm) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from megatron-lm) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->megatron-lm) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd metaseq/metaseq/"
      ],
      "metadata": {
        "id": "l8mR-d7dHf1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bc4a86-0240-4d63-950a-e7c872194366"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'metaseq/metaseq/'\n",
            "/content/Megatron-LM/metaseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the OPT model and use it for text generation"
      ],
      "metadata": {
        "id": "J8QXenZeT3Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from megatron.initialize import initialize_megatron\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "path = \"/content/opt_metaseq_1300m/model\"\n",
        "metaseq_path = \"/content/metaseq\"\n",
        "\n",
        "initialize_megatron(args_defaults={\n",
        "    \"micro_batch_size\": 1, \n",
        "    \"num_layers\": 24, \n",
        "    \"hidden_size\": 1024, \n",
        "    \"num_attention_heads\": 16,\n",
        "    \"max_position_embeddings\": 2048, # TODO check if it is the correct args\n",
        "    \"encoder_seq_length\": 2048 # TODO check if it is the correct args\n",
        "})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
        "tokenizer.save_pretrained(path)\n",
        "\n",
        "checkpoint = checkpoint_utils.load_model_ensemble_and_task(\n",
        "    [os.path.join(path, \"reshard.pt\")],\n",
        "#    [os.path.join(path, \"reshard-model_part-0.pt\"), os.path.join(path, \"reshard-model_part-1.pt\")],\n",
        "    arg_overrides={\n",
        "        \"vocab_filename\": os.path.join(path, \"vocab.json\"),\n",
        "        \"merges_filename\": os.path.join(path, \"merges.txt\"),\n",
        "    }\n",
        ")\n",
        "\n",
        "model = checkpoint[0][0].eval()\n",
        "model.to('cuda')\n",
        "start = 'Natural language processing is a subfield of'\n",
        "indexed_tokens = tokenizer.encode(start)\n",
        "for i in range(30):\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  tokens_tensor = tokens_tensor.to('cuda')\n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "    # print(i,tokenizer.decode(predicted_index))\n",
        "    indexed_tokens = indexed_tokens + [predicted_index]\n",
        "\n",
        "predicted_text = tokenizer.decode(indexed_tokens)\n",
        "print(\"------------------------------------\")\n",
        "print(start)\n",
        "print(\"------------------------------------\")\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vUMJ4Lfx8U3a",
        "outputId": "f3532535-b4aa-4da1-ebf5-9c5f37a34b12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--num-layers NUM_LAYERS]\n",
            "                             [--hidden-size HIDDEN_SIZE]\n",
            "                             [--ffn-hidden-size FFN_HIDDEN_SIZE]\n",
            "                             [--num-attention-heads NUM_ATTENTION_HEADS]\n",
            "                             [--kv-channels KV_CHANNELS]\n",
            "                             [--max-position-embeddings MAX_POSITION_EMBEDDINGS]\n",
            "                             [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]\n",
            "                             [--layernorm-epsilon LAYERNORM_EPSILON]\n",
            "                             [--apply-residual-connection-post-layernorm]\n",
            "                             [--openai-gelu] [--onnx-safe ONNX_SAFE]\n",
            "                             [--bert-no-binary-head]\n",
            "                             [--attention-dropout ATTENTION_DROPOUT]\n",
            "                             [--hidden-dropout HIDDEN_DROPOUT]\n",
            "                             [--weight-decay WEIGHT_DECAY]\n",
            "                             [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1]\n",
            "                             [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]\n",
            "                             [--sgd-momentum SGD_MOMENTUM]\n",
            "                             [--micro-batch-size MICRO_BATCH_SIZE]\n",
            "                             [--batch-size BATCH_SIZE]\n",
            "                             [--global-batch-size GLOBAL_BATCH_SIZE]\n",
            "                             [--rampup-batch-size [RAMPUP_BATCH_SIZE [RAMPUP_BATCH_SIZE ...]]]\n",
            "                             [--checkpoint-activations]\n",
            "                             [--distribute-checkpointed-activations]\n",
            "                             [--activations-checkpoint-method {uniform,block}]\n",
            "                             [--activations-checkpoint-num-layers ACTIVATIONS_CHECKPOINT_NUM_LAYERS]\n",
            "                             [--train-iters TRAIN_ITERS]\n",
            "                             [--train-samples TRAIN_SAMPLES]\n",
            "                             [--log-interval LOG_INTERVAL]\n",
            "                             [--exit-interval EXIT_INTERVAL]\n",
            "                             [--exit-duration-in-mins EXIT_DURATION_IN_MINS]\n",
            "                             [--tensorboard-dir TENSORBOARD_DIR]\n",
            "                             [--no-masked-softmax-fusion]\n",
            "                             [--no-bias-gelu-fusion]\n",
            "                             [--no-bias-dropout-fusion]\n",
            "                             [--optimizer {adam,sgd}]\n",
            "                             [--dataloader-type {single,cyclic}]\n",
            "                             [--no-async-tensor-model-parallel-allreduce]\n",
            "                             [--seed SEED] [--init-method-std INIT_METHOD_STD]\n",
            "                             [--init-method-xavier-uniform] [--lr LR]\n",
            "                             [--lr-decay-style {constant,linear,cosine}]\n",
            "                             [--lr-decay-iters LR_DECAY_ITERS]\n",
            "                             [--lr-decay-samples LR_DECAY_SAMPLES]\n",
            "                             [--lr-warmup-fraction LR_WARMUP_FRACTION]\n",
            "                             [--lr-warmup-iters LR_WARMUP_ITERS]\n",
            "                             [--lr-warmup-samples LR_WARMUP_SAMPLES]\n",
            "                             [--warmup WARMUP] [--min-lr MIN_LR]\n",
            "                             [--override-lr-scheduler]\n",
            "                             [--use-checkpoint-lr-scheduler] [--save SAVE]\n",
            "                             [--save-interval SAVE_INTERVAL] [--no-save-optim]\n",
            "                             [--no-save-rng] [--load LOAD] [--no-load-optim]\n",
            "                             [--no-load-rng] [--finetune] [--fp16] [--bf16]\n",
            "                             [--loss-scale LOSS_SCALE]\n",
            "                             [--initial-loss-scale INITIAL_LOSS_SCALE]\n",
            "                             [--min-loss-scale MIN_LOSS_SCALE]\n",
            "                             [--loss-scale-window LOSS_SCALE_WINDOW]\n",
            "                             [--hysteresis HYSTERESIS]\n",
            "                             [--fp32-residual-connection]\n",
            "                             [--no-query-key-layer-scaling]\n",
            "                             [--attention-softmax-in-fp32]\n",
            "                             [--accumulate-allreduce-grads-in-fp32]\n",
            "                             [--fp16-lm-cross-entropy]\n",
            "                             [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]\n",
            "                             [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]\n",
            "                             [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]\n",
            "                             [--model-parallel-size MODEL_PARALLEL_SIZE]\n",
            "                             [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]\n",
            "                             [--distributed-backend {nccl,gloo}]\n",
            "                             [--DDP-impl {local,torch}]\n",
            "                             [--no-contiguous-buffers-in-local-ddp]\n",
            "                             [--no-scatter-gather-tensors-in-pipeline]\n",
            "                             [--local_rank LOCAL_RANK]\n",
            "                             [--lazy-mpu-init LAZY_MPU_INIT]\n",
            "                             [--use-cpu-initialization]\n",
            "                             [--empty-unused-memory-level {0,1,2}]\n",
            "                             [--eval-iters EVAL_ITERS]\n",
            "                             [--eval-interval EVAL_INTERVAL]\n",
            "                             [--data-path [DATA_PATH [DATA_PATH ...]]]\n",
            "                             [--split SPLIT] [--vocab-file VOCAB_FILE]\n",
            "                             [--merge-file MERGE_FILE]\n",
            "                             [--vocab-extra-ids VOCAB_EXTRA_IDS]\n",
            "                             [--seq-length SEQ_LENGTH]\n",
            "                             [--encoder-seq-length ENCODER_SEQ_LENGTH]\n",
            "                             [--decoder-seq-length DECODER_SEQ_LENGTH]\n",
            "                             [--retriever-seq-length RETRIEVER_SEQ_LENGTH]\n",
            "                             [--sample-rate SAMPLE_RATE]\n",
            "                             [--mask-prob MASK_PROB]\n",
            "                             [--short-seq-prob SHORT_SEQ_PROB] [--mmap-warmup]\n",
            "                             [--num-workers NUM_WORKERS]\n",
            "                             [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer}]\n",
            "                             [--data-impl {lazy,cached,mmap,infer}]\n",
            "                             [--reset-position-ids] [--reset-attention-mask]\n",
            "                             [--eod-mask-loss] [--adlr-autoresume]\n",
            "                             [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]\n",
            "                             [--ict-head-size ICT_HEAD_SIZE]\n",
            "                             [--biencoder-projection-dim BIENCODER_PROJECTION_DIM]\n",
            "                             [--biencoder-shared-query-context-model]\n",
            "                             [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]\n",
            "                             [--titles-data-path TITLES_DATA_PATH]\n",
            "                             [--query-in-block-prob QUERY_IN_BLOCK_PROB]\n",
            "                             [--use-one-sent-docs]\n",
            "                             [--evidence-data-path EVIDENCE_DATA_PATH]\n",
            "                             [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]\n",
            "                             [--retriever-score-scaling]\n",
            "                             [--block-data-path BLOCK_DATA_PATH]\n",
            "                             [--embedding-path EMBEDDING_PATH]\n",
            "                             [--indexer-batch-size INDEXER_BATCH_SIZE]\n",
            "                             [--indexer-log-interval INDEXER_LOG_INTERVAL]\n",
            "                             [--num-classes NUM_CLASSES] [--img-dim IMG_DIM]\n",
            "                             [--num-channels NUM_CHANNELS]\n",
            "                             [--patch-dim PATCH_DIM] [--log-params-norm]\n",
            "                             [--log-num-zeros-in-grad]\n",
            "                             [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]\n",
            "                             [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]\n",
            "                             [--log-timers-to-tensorboard]\n",
            "                             [--log-batch-size-to-tensorboard]\n",
            "                             [--no-log-learnig-rate-to-tensorboard]\n",
            "                             [--no-log-loss-scale-to-tensorboard]\n",
            "                             [--log-validation-ppl-to-tensorboard]\n",
            "                             [--log-memory-to-tensorboard]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-bc12c4d2-9388-4e54-a864-7e6d9d01b83a.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}